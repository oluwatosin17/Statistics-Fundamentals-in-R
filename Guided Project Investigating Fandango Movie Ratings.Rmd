---
title: "Guided Project: Investigating Fandango Movie Rating"
Date: 14/10/2020
output: html_notebook
---
#Is Fandango Still Inflating Ratings
In October 2015, a data journalist named Walt Hickey analyzed movie ratings data and found strong evidence to suggest that Fandango's rating system was biased and dishonest (Fandango is an online movie ratings aggregator). He published his analysis in this article — a great piece of data journalism that's totally worth reading.

Fandango displays a 5-star rating system on their website, where the minimum rating is 0 stars and the maximum is 5 stars.


Hickey found that there's a significant discrepancy between the number of stars displayed to users and the actual rating, which he was able to find in the HTML of the page. He was able to find that:


The actual rating was almost always rounded up to the nearest half-star. For instance, a 4.1 movie would be rounded off to 4.5 stars, not to 4 stars, as you may expect.

In the case of 8% of the ratings analyzed, the rounding up was done to the nearest whole star. For instance, a 4.5 rating would be rounded off to 5 stars.
For one movie rating, the rounding off was completely bizarre: from a rating of 4 in the HTML of the page to a displayed rating of 5 stars.


In this project, we'll analyze more recent movie ratings data to determine whether there has been any change in Fandango's rating system after Hickey's analysis.


```{r}
library(readr)
library(tidyverse)
fandango <- read_csv('fandango_score_comparison.csv')
movie_rating <- read_csv("movie_ratings_16_17.csv")
```

```{r}
glimpse(fandango)
glimpse(movie_rating)
```

```{r}
fandango_previous <- fandango %>% select(FILM,Fandango_Stars,
                                Fandango_Ratingvalue,
                                Fandango_votes,Fandango_Difference)

fandango_after <- movie_rating %>% select(movie,year,fandango)

head(fandango_previous)
head(fandango_after)

```
The goal of this analysis is to determine whether there has been any change in Fandango's rating system after Hickey's analysis. The population of interest for this analysis is made of all the movie ratings stored on Fandango's website, regardless of the releasing year.


Because the goal is to find out whether the parameters of this population changed after Hickey's analysis, the interest here is sample the population at two different periods in time — previous and after Hickey's analysis — so the two states can be compared.


The data obtained was sampled at the moments of interest: one sample was taken previous to the analysis, and the other after the analysis. Next is to make sure that the samples are representative, otherwise a large sampling error is expected and, ultimately, wrong conclusions.


From Hickey's article and from the README.md of the data set's repository[http://github.com/fivethirtyeight/data/tree/master/fandango], the following sampling criteria was used:

- The movie must have had at least 30 fan ratings on Fandango's website at the time of sampling (Aug. 24, 2015).
- The movie must have had tickets on sale in 2015.


The sampling was clearly not random because not every movie had the same chance to be included in the sample — some movies didn't have a chance at all (like those having under 30 fan ratings or those without tickets on sale in 2015). It's questionable whether this sample is representative of the entire population of interest in this analysis. It seems more likely that it isn't, mostly because this sample is subject to temporal trends — e.g. movies in 2015 might have been outstandingly good or bad compared to other years.


The sampling conditions for other sample [https://github.com/mircealex/Movie_ratings_2016_17]

- The movie must have been released in 2016 or later.
- The movie must have had a considerable number of votes and reviews (unclear how many from the README.md or from the data).

This second sample is also not random because it is likely subject to temporal trends and it's unlikely to be representative of the population of interest for this analysis.


Both these authors had certain research questions in mind when they sampled the data, and they used a set of criteria to get a sample that would fit their questions. Their sampling method is called purposive sampling (or judgmental/selective/subjective sampling). While these samples were good enough for their research, they don't seem too useful for my analysis.


```{r}

```

#Changing the Goal of our analysis
The updated goal of this analysis is to determine whether there's any difference between Fandango's ratings for popular movies in 2015 and Fandango's ratings for popular movies in 2016.


With this new goal the two populations of interests are now:


All Fandango's ratings for popular movies released in 2015.
All Fandango's ratings for popular movies released in 2016.

For a more precise definition of the term "popular", Hickey's definition will be used for this analysis: A movie as "popular" only if it has 30 fan ratings or more on Fandango's website.

One quick way to check the representativity of this sample might be to sample randomly 10 movies from it and check the number of fan ratings on the Fandango website

```{r}
set.seed(1)
sample_n(fandango_after, size = 10)

```
After checking the number of fan ratings for the movies above, we discover that as of August 2019 Fandango no longer uses the 5-star  fan ratings described above, Instead, Fandango uses the Rotten Tomato Verified Audience Score. 

```{r}
set.seed(1)
sampled <- sample_n(fandango_after, size = 10)
# create a single column tibble of rotten tomato reviews count
reviews <- tibble(reviews = c(13569,74904,24293,4141,30183,48952,14328,59359,54765,82222))
bind_cols(sampled,reviews)


```
All ten movies sampled have well above 30 fan ratings, but it is possible that the Rotten Tomatoes Verified Audience user base is larger than the Fandango user base. I cannot really say with confidence whether these review numbers are comparable to the Fandango fan ratings. In addition, time has passed since Hickey's analysis, giving more fans an opportunity to submit reviews. So even if we did still have access to Fandango's 5-star fan ratings, we would have no way to compare the number of fan ratings we see to the number that Hickey observed. 


Let's move on to the `fandango_previous` dataframe that does include the number of fan ratings for each movie. The documentation states clearly that there're only movies with at least 30 fan ratings, but it should take only a couple of seconds to double-check here.

```{r}
sum(fandango_previous$Fandango_votes <  30)
```

```{r}
head(fandango_previous$FILM, 10)
```
If you explore the two data sets, you'll notice that there are movies with a releasing year different than 2015 or 2016. 


```{r}
unique(fandango_after$year)
```
 we'll need to isolate only the movies released in 2015 and 2016.

```{r}
fandango_previous <- fandango_previous %>%
  mutate(year = str_sub(FILM,-5,-2))

head(fandango_previous)


```
Let's examine the Frequency distribution

```{r}
fandango_previous %>% group_by(year) %>% summarise(Freq = n())
```
```{r}
table(fandango_previous$year)
table(fandango_after$year)
```

  Isolating 2015
```{r}
fandango_2015 <- fandango_previous %>% filter(year == 2015)
table(fandango_2015$year)
```
  Isolating 2016
  
```{r}
fandango_2016 <- fandango_after %>% filter(year == 2016)
table(fandango_2016$year)
```

```{r}
ggplot(data = fandango_2015, aes(x = Fandango_Stars) ,color = "blue")+geom_density()+geom_density(data = fandango_2016, aes(x = fandango), color = "red" )+
  labs(title = "Comparing distribution shapes for Fandango's rating\n(2015 vs 2016)",
x = "Stars", y = "Density")+
  scale_x_continuous(breaks = seq(0,5,by = 0.5),limits = c(0,5))
```
The plot shows that there's a clear difference between the two distributions:
- Both are left skewed
- 2016's distribution is slightly shifted to the left relative to the 2015 distribution

The slight left shift of the 2016 distribution shows that ratings were slightly lower in 2016 compared to 2015. This suggests a difference between Fandango's ratings for popular movies in 2015 and Fandango's ratings for popular movies in 2016. More specifically, the ratings in 2016 were slightly lower compared to 2015.


The plots show that there is a clear difference and a clear direction of difference between the two samples.

```{r}
fandango_2016 %>% group_by(fandango) %>% summarize(Percentage = n()/nrow(fandango_2016) *100)

fandango_2015 %>% group_by(Fandango_Stars) %>% summarize(Percentage = n()/nrow(fandango_2015) *100)

```
In 2016, very high ratings (4.5 and 5 stars) had lower percentages compared to 2015. In 2016, under 1% of the movies had a perfect rating of 5 stars, compared to 2015 when the percentage was close to 7%. Ratings of 4.5 were also more popular in 2015 — there were approximately 13% more movies rated with a 4.5 in 2015 compared to 2016.


The minimum rating is also lower in 2016 — 2.5 instead of 3 stars, the minimum of 2015. There clearly is a difference between the two frequency distributions.


For some other ratings, the percentage went up in 2016. There was a greater percentage of movies in 2016 that received 3.5 and 4 stars, compared to 2015. 3.5 and 4.0 are high ratings and this challenges the direction of the change we saw on the kernel density plots.




```{r}
mode <- function(x){
  ux <- unique(x)
  ux[which.max(tabulate(match(x,ux)))]
}


```

```{r}
summary_2015 <- fandango_2015 %>% summarise(year = "2015",
                                            mean = mean(Fandango_Stars),
                                            median = median(Fandango_Stars),
                                            mode = mode(Fandango_Stars))
summary_2015
```

```{r}
summary_2016 <- fandango_2016 %>% summarise(year = "2016",
                                            mean = mean(fandango),
                                            median = median(fandango),
                                            mode = mode(fandango))
summary_2016
```


```{r}
summary_df <- bind_rows(summary_2015,summary_2016)
summary_df


```
```{r}
summary_df <- summary_df %>%gather(key = "statistic", value = "value", - year)
```

```{r}
ggplot(data = summary_df, aes(x = statistic, y = value, fill = year)) + 
  geom_bar(stat = "identity",position = "dodge")+
  labs(title = "Comparing summary statistics: 2015 vs 2016", x = "", y = "Stars")+
  scale_y_continuous(breaks = seq(0,5,by = 0.2),limits = c(0,5))
  
```
The mean rating was lower in 2016 with approximately 0.2. This means a drop of almost 5% relative to the mean rating in 2015


```{r}
means <- summary_df %>% filter(statistic == "mean")
means %>% summarize(change = (value[1] - value[2])/ value[1] *100)

```

Change in mean is 4.84%

while the median is the same for both distributions, the mode is lower in 2016,by 0.5. Coupled with what we saw for the mean, the direction of the change we saw on the kernel density plot is confirmed on average, popular movies released in 2016 were rated slightly lower than in 2015

# Conclusion


This analysis showed that there's indeed a slight difference between Fandango's ratings for popular movies in 2015 and Fandango's ratings for popular movies in 2016. We also determined that, on average, popular movies released in 2016 were rated lower on Fandango than popular movies released in 2015.


We cannot be completely sure what caused the change, but the chances are very high that it was caused by Fandango fixing the biased rating system after Hickey's analysis.






























































